{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ocean\\Documents\\Projects\\T-AIA-901-MPL_7\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('fr_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_id = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"I love flowers\",\n",
    "    # \"Je vais à Marseille pour aller à Rome.\",\n",
    "    # \"Je vais à Paris puis à Rome pour arriver à Milan\",\n",
    "    \"Notre voyage débutera à New York et nous terminerons notre périple à Los Angeles, en passant par plusieurs villes emblématiques des États-Unis.\",\n",
    "    \"Nous allons explorer l'Europe en partant de Madrid, en passant par Paris, Amsterdam et Berlin, pour enfin nous arrêter à Prague.\",\n",
    "    \"L'aventure débutera à Tokyo, nous traverserons les montagnes jusqu'à Kyoto, puis nous achevons notre périple à Osaka.\",\n",
    "    \"Nous prévoyons de visiter l'Italie en commençant par Rome, puis de nous rendre à Florence, pour finalement conclure notre voyage à Venise.\",\n",
    "    \"Nous sommes partis de Milan pour finir à Montpellier\",\n",
    "    \"Je vais de Paris puis à Rome.\",\n",
    "    \"Nous sommes partis de Milan afin d'arriver à Montpellier\" ,\n",
    "    \"Nous sommes partis de Milan\" ,\n",
    "    \"Je vais partir de Paris et traverser la campagne française pour atteindre Nice.\" ,\n",
    "    \"Je vais partir de Pékin, explorer la Grande Muraille, puis continuer jusqu'à Xi'an avant de conclure mon voyage à Shanghai.\",\n",
    "    \"Notre voyage débutera en Australie, à Sydney, puis nous longerons la côte est pour finalement arriver à Cairns.\",\n",
    "    \"Je voudrais prendre le train de Marseille à Paris.\",\n",
    "    \"Je souhaite voyager de Bastia à Paris pour aller à Lille\",\n",
    "    \"On a pris l'avion d'Alger à Madrid pour finir à Montpellier\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    for token in doc:\n",
    "        print(\"token : \", token)\n",
    "        print('\\t', \"token.dep_ : \", token.dep_) #Je ....\n",
    "        print('\\t', \"token.pos_ : \", token.pos_) #Je ....\n",
    "        for child in token.children:\n",
    "                print('\\t', '\\t', \"child : \", child)\n",
    "                print('\\t', '\\t', \"child.dep_ : \", child.dep_)\n",
    "                print('\\t', '\\t', \"child.pos_ : \", child.pos_)\n",
    "                for subchild in child.children:\n",
    "                    print('\\t', '\\t', '\\t', \"subchild : \", subchild)\n",
    "                    print('\\t', '\\t', '\\t', \"subchild.dep : \", subchild.dep_)\n",
    "                    print('\\t', '\\t', '\\t', \"subchild.pos_ : \", subchild.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://universaldependencies.org/u/pos/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentences(phrase):\n",
    "    print(phrase) #L'aventure débutera à Tokyo, nous traverserons les montagnes jusqu'à Kyoto, puis nous achevons notre périple à Osaka.\n",
    "    doc = nlp(phrase)\n",
    "    departure = \"\"\n",
    "    destination = \"\"\n",
    "\n",
    "    for token in doc:\n",
    "        ####################### VERBE SANS PP      \n",
    "        if token.dep_ == 'ROOT' and token.pos_ == 'VERB': \n",
    "            for child in token.children:\n",
    "                ######## DEPART                            \n",
    "                if child.dep_ == 'obl:arg' and child.pos_ == 'PROPN' : # depart connecter au root\n",
    "                    departure = child.text\n",
    "                    for subchild in child.children:\n",
    "                        if subchild.dep_ == 'flat:name' and subchild.pos_ == \"PROPN\":\n",
    "\n",
    "                            departure += f\" {subchild}\"\n",
    "                    print(\"departure 1 :\", departure) #Kyoto\n",
    "\n",
    "                if child.dep_ == 'advcl' and child.pos_ == 'VERB':\n",
    "                    for subchild in child.children:\n",
    "                        print(subchild)\n",
    "                        if subchild.dep_ == 'obl:mod' and subchild.pos_ == 'PROPN':\n",
    "                            departure = subchild.text\n",
    "                        elif subchild.dep_ == 'obl:agent' and subchild.pos_ == 'PROPN':\n",
    "                            departure = subchild.text\n",
    "                    print(\"departure 2 :\", departure) #Tokyo\n",
    "\n",
    "                if child.dep_ == 'xcomp' and child.pos_ == 'VERB':\n",
    "                    for subchild in child.children:\n",
    "                        if subchild.dep_ == 'advcl' and subchild.pos_ == 'VERB':\n",
    "                            for sub in subchild.children:\n",
    "                                if sub.dep_ == 'obl:arg' and sub.pos_ == 'PROPN':\n",
    "                                    departure = sub.text\n",
    "                    print(\"departure 3 :\", departure)\n",
    "\n",
    "                \n",
    "                ######## DEST\n",
    "                if child.dep_ == 'obl:mod' and child.pos_ == 'PROPN':\n",
    "                    destination = child.text\n",
    "                if child.dep_ == 'advcl'and child.pos_ =='VERB': # arr qui est collee au verbe à l'infinitif\n",
    "                    for subchild in child.children:\n",
    "                        if subchild.dep_ == 'obl:arg' and subchild.pos_ == \"PROPN\":\n",
    "                            destination = subchild.text\n",
    "                if child.dep_ == 'conj' and child.pos_ == 'VERB':\n",
    "                    for subchild in child.children:\n",
    "                        if subchild.dep_ == 'obl:arg' and subchild.pos_ == \"PROPN\":\n",
    "                            destination = subchild.text\n",
    "                            for sub in subchild.children:\n",
    "                                if sub.dep_ == 'flat:name' and sub.pos_ == \"PROPN\":\n",
    "                                    destination += f\" {sub}\"\n",
    "                if child.dep_ == 'xcomp' and child.pos_ == 'VERB':\n",
    "                    for subchild in child.children:\n",
    "                        if subchild.dep_ == 'obl:arg' and subchild.pos_ == 'PROPN':\n",
    "                            destination = subchild.text\n",
    "        ####################### VERBE AVEC PP\n",
    "        if token.dep_ == 'ROOT' and token.pos_ == 'NOUN':\n",
    "            for child in token.children:\n",
    "                if child.dep_ == 'nmod' and child.pos_ == 'PROPN':\n",
    "                    departure = child.text\n",
    "                if child.dep_ == 'advcl'and child.pos_ =='VERB':\n",
    "                    for subchild in child.children:\n",
    "                        if subchild.dep_ == 'obl:arg' and subchild.pos_ == \"PROPN\":\n",
    "                            destination = subchild.text\n",
    "\n",
    "    print(\"Departure:\", departure)\n",
    "    print(\"Destination:\", destination, '\\n')\n",
    "    return departure, destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token :  I\n",
      "\t token.dep_ :  ROOT\n",
      "\t token.pos_ :  NOUN\n",
      "token :  love\n",
      "\t token.dep_ :  advmod\n",
      "\t token.pos_ :  ADV\n",
      "token :  flowers\n",
      "\t token.dep_ :  ROOT\n",
      "\t token.pos_ :  ADJ\n",
      "\t \t child :  love\n",
      "\t \t child.dep_ :  advmod\n",
      "\t \t child.pos_ :  ADV\n"
     ]
    }
   ],
   "source": [
    "recognize(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love flowers\n",
      "Departure: \n",
      "Destination:  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "departure, destination = process_sentences(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_trip(sentence_id):\n",
    "    if departure and destination:\n",
    "        return f\"{sentence_id},{departure},{destination}\"\n",
    "    else:\n",
    "        return f\"{sentence_id},Code,NOT_TRIP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    lang = doc.lang_\n",
    "    print(lang)\n",
    "    return lang\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def annotate_language(sentence_id, sentence):\n",
    "    lang = detect_language(sentence)\n",
    "    if lang != 'fr':\n",
    "        return f\"{sentence_id},NOT_FRENCH,\"\n",
    "    else:\n",
    "        return annotate_trip(sentence_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fr\n"
     ]
    }
   ],
   "source": [
    "result = annotate_language(sentence_id, sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,Code,NOT_TRIP'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
